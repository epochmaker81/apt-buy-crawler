import os
import requests
import pandas as pd
import gspread
from gspread_dataframe import set_with_dataframe
import xml.etree.ElementTree as ET
import time
import json
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import logging
import traceback
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- ì„¤ì • ë³€ìˆ˜ ---
SERVICE_KEY = os.getenv('SERVICE_KEY')
GOOGLE_CREDENTIALS_JSON = os.getenv('GOOGLE_CREDENTIALS_JSON')
GOOGLE_SHEET_NAME = 'ì „êµ­ ì•„íŒŒíŠ¸ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€_ëˆ„ì '
LAWD_CODE_FILE = 'lawd_code.csv'
BASE_URL = 'http://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade'

# ì‹¤í–‰ ëª¨ë“œ ì„¤ì •
RUN_MODE = os.getenv('RUN_MODE', 'TEST')

# ë‚ ì§œ ì„¤ì •
today_kst = datetime.utcnow() + timedelta(hours=9)

if RUN_MODE == 'TEST':
    MONTHS_TO_FETCH = [today_kst.strftime('%Y%m')]
    TARGET_REGIONS = ['11110']  # ì¢…ë¡œêµ¬ 1ê°œë§Œ
elif RUN_MODE == 'QUICK':
    MONTHS_TO_FETCH = [today_kst.strftime('%Y%m')]
    TARGET_REGIONS = None
else:
    MONTHS_TO_FETCH = []
    for i in range(3):
        target_date = today_kst - relativedelta(months=i)
        MONTHS_TO_FETCH.append(target_date.strftime('%Y%m'))
    TARGET_REGIONS = None

def get_google_creds():
    """Google ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    if GOOGLE_CREDENTIALS_JSON is None:
        logger.error("âŒ GOOGLE_CREDENTIALS_JSONì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    try:
        creds = json.loads(GOOGLE_CREDENTIALS_JSON)
        logger.info("âœ… Google ì¸ì¦ ì •ë³´ ë¡œë“œ ì„±ê³µ")
        return creds
    except json.JSONDecodeError as e:
        logger.error(f"âŒ GOOGLE_CREDENTIALS_JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def get_lawd_codes(filepath):
    """ì§€ì—­ ì½”ë“œ íŒŒì¼ ì½ê¸°"""
    try:
        if not os.path.exists(filepath):
            logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {filepath}")
            return []
        
        df = pd.read_csv(filepath)
        logger.info(f"ğŸ“ CSV íŒŒì¼ ì½ê¸° ì„±ê³µ: {len(df)}ê°œ ì§€ì—­")
        
        if 'code' not in df.columns:
            logger.error("âŒ 'code' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        codes = df['code'].astype(str).str.strip().tolist()
        
        # ìœ íš¨í•œ ì½”ë“œë§Œ í•„í„°ë§
        valid_codes = []
        for code in codes:
            if code and code != 'nan' and len(code) == 5 and code.isdigit():
                if not code.endswith('000'):
                    valid_codes.append(code)
        
        logger.info(f"âœ… ìœ íš¨í•œ ì§€ì—­ ì½”ë“œ: {len(valid_codes)}ê°œ")
        
        # í•„í„°ë§ ì ìš©
        if TARGET_REGIONS:
            codes = [c for c in valid_codes if c in TARGET_REGIONS]
            logger.info(f"ğŸ¯ TARGET_REGIONS í•„í„°ë§ í›„: {len(codes)}ê°œ - {codes}")
        elif RUN_MODE == 'QUICK':
            major_city_prefixes = ['11', '26', '27', '28', '29', '30', '31', '36']
            codes = [c for c in valid_codes if any(c.startswith(p) for p in major_city_prefixes)]
            logger.info(f"ğŸ™ï¸ ì£¼ìš” ë„ì‹œ í•„í„°ë§ í›„: {len(codes)}ê°œ")
        else:
            codes = valid_codes
        
        if not codes:
            logger.error("âŒ ì²˜ë¦¬í•  ìœ íš¨í•œ ì§€ì—­ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        return codes
        
    except Exception as e:
        logger.error(f"âŒ ì§€ì—­ ì½”ë“œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return []

def create_session():
    """ì•ˆì „í•œ HTTP ì„¸ì…˜ ìƒì„±"""
    session = requests.Session()
    
    # HTTP í—¤ë” ì„¤ì •
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'application/xml, text/xml, */*',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Cache-Control': 'no-cache'
    })
    
    # SSL ì„¤ì •
    session.verify = False
    
    # ì–´ëŒ‘í„° ì„¤ì • (ì¬ì‹œë„ ë¡œì§)
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
    
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    return session

def test_network_connection():
    """ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    test_urls = [
        'http://www.google.com',
        'http://openapi.molit.go.kr',
        'https://openapi.molit.go.kr'
    ]
    
    session = create_session()
    
    for url in test_urls:
        try:
            print(f"ğŸ“¡ {url} í…ŒìŠ¤íŠ¸...")
            response = session.get(url, timeout=10)
            print(f"   âœ… {url}: {response.status_code}")
        except Exception as e:
            print(f"   âŒ {url}: {str(e)[:50]}")
    
    session.close()

def fetch_data_robust(lawd_cd, deal_ymd, service_key):
    """ê°•í™”ëœ ë°ì´í„° ìˆ˜ì§‘ (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ í•´ê²°)"""
    print(f"ğŸ”„ [{lawd_cd}] ë°ì´í„° ìˆ˜ì§‘ ì‹œë„...")
    
    params = {
        'serviceKey': service_key,
        'LAWD_CD': lawd_cd,
        'DEAL_YMD': deal_ymd,
        'pageNo': '1',
        'numOfRows': '100'
    }
    
    # HTTPì™€ HTTPS ë‘˜ ë‹¤ ì‹œë„
    urls_to_try = [
        'http://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade',
        'https://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade'
    ]
    
    for url_idx, url in enumerate(urls_to_try):
        print(f"ğŸŒ [{lawd_cd}] URL {url_idx+1}/2 ì‹œë„: {'HTTP' if url_idx == 0 else 'HTTPS'}")
        
        # ì„¸ì…˜ë³„ë¡œ ì—¬ëŸ¬ ë²ˆ ì‹œë„
        for attempt in range(3):
            session = None
            try:
                print(f"   ğŸ“¡ [{lawd_cd}] ì‹œë„ {attempt+1}/3...")
                
                session = create_session()
                
                response = session.get(
                    url,
                    params=params,
                    timeout=30,
                    verify=False
                )
                
                print(f"   ğŸ“¡ [{lawd_cd}] HTTP ìƒíƒœ: {response.status_code}")
                
                if response.status_code == 200:
                    print(f"   ğŸ“„ [{lawd_cd}] ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ ({len(response.content)} bytes)")
                    
                    try:
                        root = ET.fromstring(response.content)
                        result_code = root.find('.//resultCode')
                        result_msg = root.find('.//resultMsg')
                        
                        if result_code is not None:
                            code = result_code.text
                            msg = result_msg.text if result_msg is not None else "ë©”ì‹œì§€ ì—†ìŒ"
                            
                            print(f"   ğŸ¯ [{lawd_cd}] API ê²°ê³¼: {code} - {msg}")
                            
                            if code == '00':
                                # ì„±ê³µ
                                items_element = root.find('.//items')
                                if items_element:
                                    items = items_element.findall('item')
                                    print(f"   âœ… [{lawd_cd}] ì„±ê³µ! {len(items)}ê±´ ìˆ˜ì§‘")
                                    
                                    items_data = []
                                    for item in items:
                                        item_dict = {}
                                        for child in item:
                                            item_dict[child.tag] = child.text.strip() if child.text else ''
                                        items_data.append(item_dict)
                                    
                                    if items_data:
                                        print(f"   ğŸ“Š [{lawd_cd}] ì²« ë²ˆì§¸ ë°ì´í„° ì»¬ëŸ¼: {list(items_data[0].keys())[:5]}...")
                                    
                                    session.close()
                                    return items_data
                                else:
                                    print(f"   ğŸ“­ [{lawd_cd}] items ì—˜ë¦¬ë¨¼íŠ¸ ì—†ìŒ")
                                    session.close()
                                    return []
                            elif code == '99':
                                print(f"   ğŸ“­ [{lawd_cd}] ë°ì´í„° ì—†ìŒ (ì •ìƒ)")
                                session.close()
                                return []
                            elif code == '04':
                                print(f"   âŒ [{lawd_cd}] SERVICE_KEY ì˜¤ë¥˜")
                                session.close()
                                return []
                            elif code == '05':
                                print(f"   âŒ [{lawd_cd}] ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ")
                                session.close()
                                return []
                            else:
                                print(f"   âŒ [{lawd_cd}] API ì˜¤ë¥˜: {code}")
                                session.close()
                                return []
                        else:
                            print(f"   âŒ [{lawd_cd}] ê²°ê³¼ ì½”ë“œ ì—†ìŒ")
                            
                    except ET.ParseError as e:
                        print(f"   âŒ [{lawd_cd}] XML íŒŒì‹± ì˜¤ë¥˜: {str(e)[:30]}")
                        print(f"   ğŸ“„ ì‘ë‹µ ë‚´ìš© (ì²« 200ì): {response.text[:200]}")
                        
                else:
                    print(f"   âŒ [{lawd_cd}] HTTP ì˜¤ë¥˜: {response.status_code}")
                    
            except requests.exceptions.ConnectTimeout:
                print(f"   â° [{lawd_cd}] ì—°ê²° íƒ€ì„ì•„ì›ƒ")
            except requests.exceptions.ReadTimeout:
                print(f"   â° [{lawd_cd}] ì½ê¸° íƒ€ì„ì•„ì›ƒ")
            except requests.exceptions.ConnectionError as e:
                print(f"   ğŸŒ [{lawd_cd}] ì—°ê²° ì˜¤ë¥˜: {str(e)[:50]}")
            except Exception as e:
                print(f"   âŒ [{lawd_cd}] ì˜ˆì™¸: {str(e)[:50]}")
            finally:
                if session:
                    session.close()
            
            # ì¬ì‹œë„ ì „ ëŒ€ê¸°
            if attempt < 2:
                wait_time = (attempt + 1) * 2
                print(f"   â³ [{lawd_cd}] {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
    
    print(f"   âŒ [{lawd_cd}] ëª¨ë“  ì‹œë„ ì‹¤íŒ¨")
    return []

def create_unique_id(df):
    """ê³ ìœ  ID ìƒì„±"""
    if df.empty:
        return df
    
    id_cols = ['ê±°ë˜ê¸ˆì•¡', 'ë…„', 'ì›”', 'ì¼', 'ì „ìš©ë©´ì ', 'ì§€ë²ˆ', 'ì¸µ']
    valid_cols = [col for col in id_cols if col in df.columns]
    
    if valid_cols:
        df['unique_id'] = df[valid_cols].astype(str).agg('_'.join, axis=1)
    return df

def upload_to_sheet(df_new, df_existing, worksheet):
    """Google Sheetsì— ì—…ë¡œë“œ"""
    if df_new.empty:
        print("ğŸ“­ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0, df_existing
    
    print(f"ğŸ“Š ìƒˆ ë°ì´í„°: {len(df_new)}ê±´")
    print(f"ğŸ“‹ ì»¬ëŸ¼: {list(df_new.columns)}")
    
    df_new = create_unique_id(df_new)
    
    if not df_existing.empty:
        if 'unique_id' not in df_existing.columns:
            df_existing = create_unique_id(df_existing)
        
        newly_added = df_new[~df_new['unique_id'].isin(df_existing['unique_id'])].copy()
        print(f"ğŸ” ì¤‘ë³µ ì œê±° í›„: {len(newly_added)}ê±´")
    else:
        newly_added = df_new.copy()
        print("ğŸ“ ê¸°ì¡´ ë°ì´í„° ì—†ìŒ - ëª¨ë“  ë°ì´í„° ì¶”ê°€")
    
    if newly_added.empty:
        print("â„¹ï¸ ì¶”ê°€í•  ìƒˆ ë°ì´í„° ì—†ìŒ (ëª¨ë‘ ì¤‘ë³µ)")
        return 0, df_existing
    
    count = len(newly_added)
    df_to_upload = newly_added.drop(columns=['unique_id'], errors='ignore')
    
    try:
        if worksheet.row_count < 2:
            print("ğŸ“ ë¹ˆ ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€")
            set_with_dataframe(worksheet, df_to_upload, include_index=False)
        else:
            print("ğŸ“ ê¸°ì¡´ ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€")
            headers = worksheet.row_values(1)
            
            aligned = pd.DataFrame(columns=headers)
            for col in headers:
                if col in df_to_upload.columns:
                    aligned[col] = df_to_upload[col]
                else:
                    aligned[col] = ''
            
            worksheet.append_rows(aligned.values.tolist(), value_input_option='USER_ENTERED')
        
        df_existing_updated = pd.concat([df_existing, newly_added], ignore_index=True)
        print(f"âœ… ì—…ë¡œë“œ ì„±ê³µ: {count}ê±´ ì¶”ê°€ë¨")
        return count, df_existing_updated
        
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        logger.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return -1, df_existing

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    start_time = time.time()
    
    print("ğŸš€ ===== ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì—…ë°ì´íŠ¸ ì‹œì‘ =====")
    print(f"ğŸ”§ ì‹¤í–‰ ëª¨ë“œ: {RUN_MODE}")
    print(f"ğŸ“… ëŒ€ìƒ ì›”: {MONTHS_TO_FETCH}")
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not SERVICE_KEY:
        print("âŒ SERVICE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    if not GOOGLE_CREDENTIALS_JSON:
        print("âŒ GOOGLE_CREDENTIALS_JSONì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… SERVICE_KEY: {len(SERVICE_KEY)}ì")
    print(f"âœ… GOOGLE_CREDENTIALS_JSON: ì„¤ì •ë¨")
    
    # ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸
    test_network_connection()
    
    # ì§€ì—­ ì½”ë“œ ë¡œë“œ
    lawd_codes = get_lawd_codes(LAWD_CODE_FILE)
    if not lawd_codes:
        print("âŒ ìœ íš¨í•œ ì§€ì—­ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì§€ì—­ ì½”ë“œ: {len(lawd_codes)}ê°œ - {lawd_codes}")
    
    # Google Sheets ì´ˆê¸°í™”
    print("ğŸ“Š Google Sheets ì´ˆê¸°í™” ì¤‘...")
    try:
        creds = get_google_creds()
        if not creds:
            return
        
        gc = gspread.service_account_from_dict(creds)
        print("âœ… Google Sheets í´ë¼ì´ì–¸íŠ¸ ìƒì„±")
        
        try:
            sh = gc.open(GOOGLE_SHEET_NAME)
            print(f"âœ… ê¸°ì¡´ ì‹œíŠ¸ ì—´ê¸°: {GOOGLE_SHEET_NAME}")
        except gspread.exceptions.SpreadsheetNotFound:
            sh = gc.create(GOOGLE_SHEET_NAME)
            print(f"ğŸ†• ìƒˆ ì‹œíŠ¸ ìƒì„±: {GOOGLE_SHEET_NAME}")
        
        worksheet = sh.get_worksheet(0)
        sheet_url = sh.url
        print(f"ğŸ”— ì‹œíŠ¸ URL: {sheet_url}")
        
        # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
        existing_records = worksheet.get_all_records()
        df_existing = pd.DataFrame(existing_records)
        
        if not df_existing.empty:
            df_existing.columns = df_existing.columns.str.strip()
            print(f"ğŸ“Š ê¸°ì¡´ ë°ì´í„°: {len(df_existing)}ê±´")
        else:
            print("ğŸ“ ê¸°ì¡´ ë°ì´í„° ì—†ìŒ")
            
    except Exception as e:
        print(f"âŒ Google Sheets ì˜¤ë¥˜: {e}")
        logger.error(traceback.format_exc())
        return
    
    total_added = 0
    
    # ë°ì´í„° ìˆ˜ì§‘ ë° ì—…ë¡œë“œ
    for month in MONTHS_TO_FETCH:
        print(f"\nğŸ“… ===== {month} ë°ì´í„° ìˆ˜ì§‘ =====")
        
        monthly_data = []
        
        for i, code in enumerate(lawd_codes):
            print(f"\n[{i+1}/{len(lawd_codes)}] {code} ì²˜ë¦¬...")
            data = fetch_data_robust(code, month, SERVICE_KEY)
            
            if data:
                monthly_data.extend(data)
                print(f"   âœ… {len(data)}ê±´ ìˆ˜ì§‘ë¨")
            else:
                print(f"   ğŸ“­ ë°ì´í„° ì—†ìŒ")
            
            time.sleep(2)  # API í˜¸ì¶œ ê°„ê²© ì¦ê°€
        
        print(f"\nğŸ“Š {month} ì´ ìˆ˜ì§‘: {len(monthly_data)}ê±´")
        
        if not monthly_data:
            print(f"âš ï¸ {month}: ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")
            print("ê°€ëŠ¥í•œ ì›ì¸:")
            print("1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ")
            print("2. SERVICE_KEY ê¶Œí•œ ë¬¸ì œ")
            print("3. API ì„œë²„ ì¼ì‹œì  ë¬¸ì œ")
            continue
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_month = pd.DataFrame(monthly_data)
        df_month.columns = df_month.columns.str.strip()
        
        print(f"ğŸ“¤ Google Sheetsì— ì—…ë¡œë“œ ì¤‘...")
        added, df_existing = upload_to_sheet(df_month, df_existing, worksheet)
        
        if added > 0:
            total_added += added
            print(f"âœ… {month}: {added}ê±´ ì¶”ê°€ë¨")
        elif added == 0:
            print(f"â„¹ï¸ {month}: ìƒˆë¡œìš´ ë°ì´í„° ì—†ìŒ")
        else:
            print(f"âŒ {month}: ì—…ë¡œë“œ ì‹¤íŒ¨")
    
    # ì™„ë£Œ
    elapsed = time.time() - start_time
    print(f"\nğŸ‰ ===== ì™„ë£Œ =====")
    print(f"ğŸ“Š ì´ {total_added}ê±´ ì¶”ê°€")
    print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed//60:.0f}ë¶„ {elapsed%60:.0f}ì´ˆ")
    print(f"ğŸ”— ê²°ê³¼: {sheet_url}")

if __name__ == '__main__':
    main()
